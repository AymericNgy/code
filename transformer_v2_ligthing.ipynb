{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source : https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:32.216044500Z",
     "start_time": "2024-02-15T15:08:32.152535500Z"
    }
   },
   "id": "f86f6c1d7db0f65e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import lightning as L\n",
    "\n",
    "class MultiHeadAttention(L.LightningModule):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:33.689196100Z",
     "start_time": "2024-02-15T15:08:33.607437Z"
    }
   },
   "id": "45a8c844acbfe20a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(L.LightningModule):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:38.253704700Z",
     "start_time": "2024-02-15T15:08:38.194158600Z"
    }
   },
   "id": "642221a5b86ad9f2"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class PositionalEncoding(L.LightningModule):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:41.851306900Z",
     "start_time": "2024-02-15T15:08:41.759337100Z"
    }
   },
   "id": "23383aee7b026ae1"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class EncoderLayer(L.LightningModule):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:46.272015400Z",
     "start_time": "2024-02-15T15:08:46.232900200Z"
    }
   },
   "id": "24d725033ce3d1ea"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class DecoderLayer(L.LightningModule):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:08:49.789124900Z",
     "start_time": "2024-02-15T15:08:49.557997200Z"
    }
   },
   "id": "ebbfb10617c46925"
  },
  {
   "cell_type": "markdown",
   "source": [
    " # inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28fe33fab7c0ba4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_sequences_batch(transformer, src_data, max_length=20):\n",
    "    transformer.eval()  # Mettre le modèle en mode évaluation\n",
    "    with torch.no_grad():\n",
    "        batch_size = src_data.size(0)\n",
    "        generated_sequences = [[START_TOKEN_TRANSFORMER] for _ in range(batch_size)]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            # Obtenez les prédictions pour la séquence actuelle\n",
    "            generated_sequences_torch = [torch.tensor(seq).unsqueeze(0).to(dtype=torch.long).to(src_data.device) for seq\n",
    "                                         in generated_sequences]\n",
    "            output = transformer(src_data, torch.cat(generated_sequences_torch, dim=0))\n",
    "\n",
    "            # Utiliser argmax pour obtenir l'indice du maximum du dernier predit\n",
    "            next_tokens = torch.argmax(output[:, -1, :], dim=1)\n",
    "\n",
    "            # Ajouter les prédictions aux séquences générées\n",
    "            for i in range(batch_size):\n",
    "                generated_sequences[i].append(next_tokens[i].item())\n",
    "                \n",
    "\n",
    "        return torch.tensor(generated_sequences).to(device)\n",
    "\n",
    "\n",
    "# # Exemple d'utilisation avec un batch de données source\n",
    "# src_data_batch = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]]).to(dtype=torch.long).to(device)\n",
    "# generated_sequences_batch = generate_sequences_batch(transformer, src_data_batch, max_length=max_seq_length)\n",
    "# print(\"Generated Sequences Batch:\", generated_sequences_batch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d934aa242fe95046"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "class Transformer(L.LightningModule):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=NB_MAX_TOKEN_TRANSFORMER)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (txt, cmp_input), cmp_output = batch\n",
    "        output = transformer(txt, cmp_input)\n",
    "        loss = self.criterion(output.contiguous().view(-1, tgt_vocab_size), cmp_output.contiguous().view(-1))\n",
    "\n",
    "        # bug\n",
    "\n",
    "        # output_inference = generate_sequences_batch(self, txt, max_length=MAX_LENGTH)\n",
    "        # target_inference = replace_padding_by_end_token(add_start_token(cmp_output))\n",
    "        # loss_inference = nn.CrossEntropyLoss(output_inference,target_inference)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log('train_acc_step', self.accuracy)\n",
    "        # self.lof(\"inference_loss\", loss_inference)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "        return optimizer\n",
    "        \n",
    "\n",
    "# [!] pas de decalage entre decode input et output?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:50:00.272305600Z",
     "start_time": "2024-02-15T15:50:00.006543700Z"
    }
   },
   "id": "bd05a5ba384eb75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LZ77 Algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac4c0c0efa4a864"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0598af7d601f25"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# https://github.com/manassra/LZ77-Compressor\n",
    "\n",
    "import math\n",
    "from bitarray import bitarray\n",
    "\n",
    "\n",
    "class LZ77Compressor:\n",
    "    \"\"\"\n",
    "    A simplified implementation of the LZ77 Compression Algorithm\n",
    "    \"\"\"\n",
    "    MAX_WINDOW_SIZE = 400\n",
    "\n",
    "    def __init__(self, window_size=20):\n",
    "        self.window_size = min(window_size, self.MAX_WINDOW_SIZE)\n",
    "        self.lookahead_buffer_size = 15  # length of match is at most 4 bits\n",
    "\n",
    "    def compress(self, input_file_path, output_file_path=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the path of an input file, its content is compressed by applying a simple\n",
    "        LZ77 compression algorithm.\n",
    "\n",
    "        The compressed format is:\n",
    "        0 bit followed by 8 bits (1 byte character) when there are no previous matches\n",
    "            within window\n",
    "        1 bit followed by 12 bits pointer (distance to the start of the match from the\n",
    "            current position) and 4 bits (length of the match)\n",
    "\n",
    "        If a path to the output file is provided, the compressed data is written into\n",
    "        a binary file. Otherwise, it is returned as a bitarray\n",
    "\n",
    "        if verbose is enabled, the compression description is printed to standard output\n",
    "        \"\"\"\n",
    "        data = None\n",
    "        i = 0\n",
    "        output_buffer = bitarray(endian='big')\n",
    "\n",
    "        # read the input file\n",
    "        try:\n",
    "            with open(input_file_path, 'rb') as input_file:\n",
    "                data = input_file.read()\n",
    "        except IOError:\n",
    "            print('Could not open input file ...')\n",
    "            raise\n",
    "\n",
    "        while i < len(data):\n",
    "            # print(i)\n",
    "\n",
    "            match = self.findLongestMatch(data, i)\n",
    "\n",
    "            if match:\n",
    "                # Add 1 bit flag, followed by 12 bit for distance, and 4 bit for the length\n",
    "                # of the match\n",
    "                (bestMatchDistance, bestMatchLength) = match\n",
    "\n",
    "                output_buffer.append(True)\n",
    "                output_buffer.frombytes(bytes([bestMatchDistance >> 4]))\n",
    "                output_buffer.frombytes(bytes([((bestMatchDistance & 0xf) << 4) | bestMatchLength]))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"<1, %i, %i>\" % (bestMatchDistance, bestMatchLength), end='')\n",
    "\n",
    "                i += bestMatchLength\n",
    "\n",
    "            else:\n",
    "                # No useful match was found. Add 0 bit flag, followed by 8 bit for the character\n",
    "                output_buffer.append(False)\n",
    "                output_buffer.frombytes(bytes([data[i]]))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"<0, %s>\" % data[i], end='')\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        # fill the buffer with zeros if the number of bits is not a multiple of 8\n",
    "        output_buffer.fill()\n",
    "\n",
    "        # write the compressed data into a binary file if a path is provided\n",
    "        if output_file_path:\n",
    "            try:\n",
    "                with open(output_file_path, 'wb') as output_file:\n",
    "                    output_file.write(output_buffer.tobytes())\n",
    "                    print(\"File was compressed successfully and saved to output path ...\")\n",
    "                    return None\n",
    "            except IOError:\n",
    "                print('Could not write to output file path. Please check if the path is correct ...')\n",
    "                raise\n",
    "\n",
    "        # an output file path was not provided, return the compressed data\n",
    "        return output_buffer\n",
    "\n",
    "    def findLongestMatch(self, data, current_position):\n",
    "        \"\"\"\n",
    "        Finds the longest match to a substring starting at the current_position\n",
    "        in the lookahead buffer from the history window\n",
    "        \"\"\"\n",
    "        end_of_buffer = min(current_position + self.lookahead_buffer_size, len(data) + 1)\n",
    "\n",
    "        best_match_distance = -1\n",
    "        best_match_length = -1\n",
    "\n",
    "        # Optimization: Only consider substrings of length 2 and greater, and just\n",
    "        # output any substring of length 1 (8 bits uncompressed is better than 13 bits\n",
    "        # for the flag, distance, and length)\n",
    "        for j in range(current_position + 2, end_of_buffer):\n",
    "\n",
    "            start_index = max(0, current_position - self.window_size)\n",
    "            substring = data[current_position:j]\n",
    "\n",
    "            for i in range(start_index, current_position):\n",
    "\n",
    "                repetitions = len(substring) // (current_position - i)\n",
    "\n",
    "                last = len(substring) % (current_position - i)\n",
    "\n",
    "                matched_string = data[i:current_position] * repetitions + data[i:i + last]\n",
    "\n",
    "                if matched_string == substring and len(substring) > best_match_length:\n",
    "                    best_match_distance = current_position - i\n",
    "                    best_match_length = len(substring)\n",
    "\n",
    "        if best_match_distance > 0 and best_match_length > 0:\n",
    "            return (best_match_distance, best_match_length)\n",
    "        return None\n",
    "\n",
    "    def compress_in_place(self, data, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the path of an input file, its content is compressed by applying a simple\n",
    "        LZ77 compression algorithm.\n",
    "\n",
    "        The compressed format is:\n",
    "        0 bit followed by 8 bits (1 byte character) when there are no previous matches\n",
    "            within window\n",
    "        1 bit followed by 12 bits pointer (distance to the start of the match from the\n",
    "            current position) and 4 bits (length of the match)\n",
    "\n",
    "        If a path to the output file is provided, the compressed data is written into\n",
    "        a binary file. Otherwise, it is returned as a bitarray\n",
    "\n",
    "        if verbose is enabled, the compression description is printed to standard output\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        output_buffer = bitarray(endian='big')\n",
    "\n",
    "        while i < len(data):\n",
    "\n",
    "            # print(i)\n",
    "\n",
    "            match = self.findLongestMatch(data, i)\n",
    "\n",
    "            if match:\n",
    "                # Add 1 bit flag, followed by 12 bit for distance, and 4 bit for the length\n",
    "                # of the match\n",
    "                (bestMatchDistance, bestMatchLength) = match\n",
    "\n",
    "                output_buffer.append(True)\n",
    "                output_buffer.frombytes(bytes([bestMatchDistance >> 4]))\n",
    "                output_buffer.frombytes(bytes([((bestMatchDistance & 0xf) << 4) | bestMatchLength]))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"<1, %i, %i>\" % (bestMatchDistance, bestMatchLength), end='')\n",
    "\n",
    "                i += bestMatchLength\n",
    "\n",
    "            else:\n",
    "                # No useful match was found. Add 0 bit flag, followed by 8 bit for the character\n",
    "                output_buffer.append(False)\n",
    "                output_buffer.frombytes(bytes([data[i]]))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"<0, %s>\" % data[i], end='')\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        # fill the buffer with zeros if the number of bits is not a multiple of 8\n",
    "        output_buffer.fill()\n",
    "\n",
    "        # an output file path was not provided, return the compressed data\n",
    "        return output_buffer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T13:54:15.971853700Z",
     "start_time": "2024-02-15T13:54:15.915401700Z"
    }
   },
   "id": "fd58dd70c0a6aa8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# functions for treat data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ba789e5d66926dd"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def bytes2torch(bytes):\n",
    "    if not type(bytes) is list:\n",
    "        data_integers = list(bytes)\n",
    "\n",
    "    data_tensor = torch.tensor(data_integers, dtype=torch.uint8)\n",
    "\n",
    "    return data_tensor\n",
    "\n",
    "\n",
    "def tokenizer(byte_tensor, length, device):\n",
    "    \"\"\"\"\n",
    "    :param byte_tensor: torch tensor uint8\n",
    "    :param length: length of the output, complete with padding if shorter\n",
    "    :return: torch tensor int16\n",
    "    \"\"\"\n",
    "    new_tensor = (byte_tensor[:length] + 1)\n",
    "    zero_tensor = torch.zeros(length, dtype=torch.int64).to(device)\n",
    "    zero_tensor[:new_tensor.size(0)] = new_tensor\n",
    "\n",
    "    return zero_tensor\n",
    "\n",
    "\n",
    "def tokenizer_for_transformer(byte_tensor, length, device, start_token=None, end_token=None):\n",
    "    new_tensor = (byte_tensor[:length] + 1)\n",
    "\n",
    "    if start_token and end_token:\n",
    "        new_tensor = torch.cat([torch.tensor([start_token]), new_tensor, torch.tensor([end_token])])\n",
    "    elif start_token:\n",
    "        new_tensor = torch.cat([torch.tensor([start_token]), new_tensor])\n",
    "    elif end_token:\n",
    "        new_tensor = torch.cat([new_tensor, torch.tensor([end_token])])\n",
    "\n",
    "    zero_tensor = torch.zeros(length, dtype=torch.int64).to(device)\n",
    "    zero_tensor[:new_tensor.size(0)] = new_tensor\n",
    "\n",
    "    return zero_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T13:56:19.712119100Z",
     "start_time": "2024-02-15T13:56:19.685061600Z"
    }
   },
   "id": "f23d174a65bf28e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataSet with files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a104d0edfe707234"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from generate_data import NB_MAX_TOKEN\n",
    "\n",
    "START_TOKEN_TRANSFORMER = NB_MAX_TOKEN\n",
    "END_TOKEN_TRANSFORMER = NB_MAX_TOKEN + 1\n",
    "\n",
    "\n",
    "# [!] arg changed\n",
    "class LZ77Dataset(Dataset):\n",
    "    def __init__(self, length, device, features_folder=\"./data_LZ77/text\", targets_folder=\"./data_LZ77/compress\",\n",
    "                 for_transformer=False, start_token=None, end_token=None):\n",
    "        self.features_folder = features_folder\n",
    "        self.targets_folder = targets_folder\n",
    "        self.for_transformer = for_transformer\n",
    "        self.length = length\n",
    "        self.device = device\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "\n",
    "        # Listes des noms de fichiers dans les dossiers\n",
    "        self.feature_files = os.listdir(features_folder)\n",
    "        self.target_files = os.listdir(targets_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.feature_files), len(self.target_files))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_path = os.path.join(self.features_folder, self.feature_files[idx])\n",
    "        target_path = os.path.join(self.targets_folder, self.target_files[idx])\n",
    "\n",
    "        with open(feature_path, 'rb') as feature_file:\n",
    "            feature_data = feature_file.read()\n",
    "        with open(target_path, 'rb') as target_file:\n",
    "            target_data = target_file.read()\n",
    "\n",
    "        if self.for_transformer:\n",
    "            encoder_input = tokenizer_for_transformer(bytes2torch(feature_data), self.length, self.device,\n",
    "                                                      start_token=START_TOKEN_TRANSFORMER,\n",
    "                                                      end_token=END_TOKEN_TRANSFORMER)\n",
    "            decoder_input = tokenizer_for_transformer(bytes2torch(target_data), self.length, self.device,\n",
    "                                                      start_token=START_TOKEN_TRANSFORMER, end_token=None)\n",
    "            feature_data = (encoder_input, decoder_input)\n",
    "            target_data = tokenizer_for_transformer(bytes2torch(target_data), self.length, self.device,\n",
    "                                                    start_token=None, end_token=END_TOKEN_TRANSFORMER)\n",
    "\n",
    "        else:\n",
    "            feature_data = tokenizer(bytes2torch(feature_data), self.length, self.device)\n",
    "            target_data = tokenizer(bytes2torch(target_data), self.length, self.device)\n",
    "\n",
    "        return feature_data, target_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T13:56:08.870958900Z",
     "start_time": "2024-02-15T13:56:08.781341300Z"
    }
   },
   "id": "cf24e19601d1341e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# function to create Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68df5b4025b13e2e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def generate_random_ascii_bytes(length, repetition_probability=0.65):\n",
    "    ascii_characters = string.ascii_letters + string.digits + string.punctuation\n",
    "    dim = len(ascii_characters)\n",
    "    random_ascii_text = ''\n",
    "\n",
    "    for _ in range(length):\n",
    "        if random.random() < repetition_probability and random_ascii_text:\n",
    "            # Répétition d'un caractère existant\n",
    "            random_ascii_text += random.choice(random_ascii_text)\n",
    "        else:\n",
    "            # Choix aléatoire d'un nouveau caractère\n",
    "            random_ascii_text += random.choice(ascii_characters)\n",
    "\n",
    "    # Convertir la chaîne de caractères en bytes en utilisant encode\n",
    "    random_ascii_bytes = random_ascii_text.encode('utf-8')\n",
    "    return random_ascii_bytes, dim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T13:56:06.368103Z",
     "start_time": "2024-02-15T13:56:06.320842400Z"
    }
   },
   "id": "5daf9fe6092ba118"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Realtime"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb84bf62bdc17a7"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_sample_in_place(compressor, length, repetition_probability):\n",
    "    text, dim = generate_random_ascii_bytes(length, repetition_probability)\n",
    "    compress = compressor.compress_in_place(text)\n",
    "\n",
    "    return text, compress\n",
    "\n",
    "\n",
    "def bits_to_bytes(bits):\n",
    "    return bits.tobytes()\n",
    "\n",
    "\n",
    "class LZ77Dataset_current_creation(Dataset):\n",
    "    def __init__(self, length_sentence, device, repetition_probability, size_data_set, lenght_max, for_transformer):\n",
    "        self.compressor = LZ77Compressor()\n",
    "        self.length_sentence = length_sentence\n",
    "        self.device = device\n",
    "        self.repetition_probability = repetition_probability\n",
    "        self.size_data_set = size_data_set\n",
    "        self.lenght_max = lenght_max\n",
    "        self.for_transformer = for_transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size_data_set\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, compress = create_sample_in_place(self.compressor, self.length_sentence, self.repetition_probability)\n",
    "\n",
    "        if self.for_transformer:\n",
    "            encoder_input = tokenizer_for_transformer(bytes2torch(text), self.lenght_max, self.device,\n",
    "                                                      start_token=START_TOKEN_TRANSFORMER,\n",
    "                                                      end_token=END_TOKEN_TRANSFORMER)\n",
    "            decoder_input = tokenizer_for_transformer(bytes2torch(bits_to_bytes(compress)), self.lenght_max,\n",
    "                                                      self.device,\n",
    "                                                      start_token=START_TOKEN_TRANSFORMER, end_token=None)\n",
    "            feature_data = (encoder_input, decoder_input)\n",
    "            target_data = tokenizer_for_transformer(bytes2torch(bits_to_bytes(compress)), self.lenght_max, self.device,\n",
    "                                                    start_token=None, end_token=END_TOKEN_TRANSFORMER)\n",
    "\n",
    "        else:\n",
    "            feature_data = tokenizer(bytes2torch(text), self.lenght_max, self.device)\n",
    "            target_data = tokenizer(bytes2torch(bits_to_bytes(compress)), self.lenght_max, self.device)\n",
    "\n",
    "        # feature_data = tokenizer(bytes2torch(text), self.lenght_max, self.device)\n",
    "        # target_data = tokenizer(bytes2torch(bits_to_bytes(compress)), self.lenght_max, self.device)\n",
    "\n",
    "        return feature_data, target_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:09:06.599034400Z",
     "start_time": "2024-02-15T15:09:06.567815600Z"
    }
   },
   "id": "e2310627a11f6ac3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# set train and test loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e559051c243a"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature and target : (tensor([257, 123, 123, 123,  34, 123,  34, 123,  34, 123, 123, 258,   0,   0,\n",
      "          0,   0,   0], device='cuda:0'), tensor([257,  62,  65,   5, 133,  49,   3,  84, 209,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0], device='cuda:0')) tensor([ 62,  65,   5, 133,  49,   3,  84, 209, 258,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# [!] padding avec zero a bien faire attention que identique\n",
    "# [!] verifier que les to(device) sont dans les init ou a la creation\n",
    "# [!] augmenter taille des batches\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from generate_data import SENTENCE_LENGTH\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # [!] essayer d'enlever le plus de device possible\n",
    "\n",
    "SENTENCE_LENGTH = 10  # [!] only if on realtime creation\n",
    "NB_SPECIAL_TOKEN = 2\n",
    "NB_MAX_TOKEN_TRANSFORMER = NB_MAX_TOKEN + NB_SPECIAL_TOKEN\n",
    "MAX_LENGTH = SENTENCE_LENGTH + 5 + NB_SPECIAL_TOKEN\n",
    "length_sentence = SENTENCE_LENGTH\n",
    "repetition_probability = 0.8\n",
    "size_data_set = 256\n",
    "batch_size = 256\n",
    "test_proportion = 0.8\n",
    "\n",
    "lz77_dataset = LZ77Dataset_current_creation(length_sentence, device, repetition_probability, size_data_set, MAX_LENGTH,\n",
    "                                            for_transformer=True)\n",
    "\n",
    "test_size = int(test_proportion * len(lz77_dataset))\n",
    "\n",
    "train_dataset, test_dataset = random_split(lz77_dataset, [len(lz77_dataset) - test_size, test_size])\n",
    "\n",
    "lz77_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "lz77_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch in lz77_train_loader:\n",
    "    (txt_example, cmp_input_example), cmp_output_example = batch\n",
    "    break\n",
    "\n",
    "print(\"feature and target :\", (txt_example[0], cmp_input_example[0]), cmp_output_example[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:09:10.064040100Z",
     "start_time": "2024-02-15T15:09:09.857062300Z"
    }
   },
   "id": "b06527c5bb88a790"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "src_vocab_size = NB_MAX_TOKEN_TRANSFORMER\n",
    "tgt_vocab_size = NB_MAX_TOKEN_TRANSFORMER\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = MAX_LENGTH\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length,\n",
    "                          dropout).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:50:05.847551500Z",
     "start_time": "2024-02-15T15:50:04.881418700Z"
    }
   },
   "id": "ebb87f7232177a9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55871aed3c203f1"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequences Batch: tensor([[257,  33, 224, 192, 249,  33, 224,  13,  33, 167,  88, 125,  97,  88,\n",
      "          97,  97,  97,  88],\n",
      "        [257, 240, 150,  88,   1, 150,  88,  88,  88,  88,  88,  88, 240,   5,\n",
      "         240,   5, 240,   9]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences_batch(transformer, src_data, max_length=20):\n",
    "    transformer.eval()  # Mettre le modèle en mode évaluation\n",
    "    with torch.no_grad():\n",
    "        batch_size = src_data.size(0)\n",
    "        generated_sequences = [[START_TOKEN_TRANSFORMER] for _ in range(batch_size)]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            # Obtenez les prédictions pour la séquence actuelle\n",
    "            generated_sequences_torch = [torch.tensor(seq).unsqueeze(0).to(dtype=torch.long).to(src_data.device) for seq\n",
    "                                         in generated_sequences]\n",
    "            output = transformer(src_data, torch.cat(generated_sequences_torch, dim=0))\n",
    "\n",
    "            # Utiliser argmax pour obtenir l'indice du maximum du dernier predit\n",
    "            next_tokens = torch.argmax(output[:, -1, :], dim=1)\n",
    "\n",
    "            # Ajouter les prédictions aux séquences générées\n",
    "            for i in range(batch_size):\n",
    "                generated_sequences[i].append(next_tokens[i].item())\n",
    "\n",
    "        return torch.tensor(generated_sequences).to(device)\n",
    "\n",
    "\n",
    "# Exemple d'utilisation avec un batch de données source\n",
    "src_data_batch = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]]).to(dtype=torch.long).to(device)\n",
    "generated_sequences_batch = generate_sequences_batch(transformer, src_data_batch, max_length=max_seq_length)\n",
    "print(\"Generated Sequences Batch:\", generated_sequences_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:44:19.536428700Z",
     "start_time": "2024-02-15T15:44:18.930800300Z"
    }
   },
   "id": "930afb14b72482da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1cb050e406b925"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def mean_error(batch_1, batch_2):\n",
    "    errors = (batch_1 != batch_2).float()  # 1 si différent, 0 si identique\n",
    "    error_rate = torch.mean(errors).item()  # Calculer la moyenne des erreurs\n",
    "    return error_rate\n",
    "\n",
    "\n",
    "batch_1 = torch.tensor([[1.0, 2.2, 3.1], [1.0, 2.0, 3.0]])\n",
    "batch_2 = torch.tensor([[1.1, 2.4, 3.0], [1.0, 2.0, 3.0]])\n",
    "\n",
    "print(mean_error(batch_1, batch_2))\n",
    "\n",
    "def replace_padding_by_end_token(batch):\n",
    "    return torch.where(batch == 0, END_TOKEN_TRANSFORMER, batch)\n",
    "\n",
    "def add_start_token(batch):\n",
    "    return torch.cat([torch.full((batch.size(0), 1), fill_value=START_TOKEN_TRANSFORMER).to(device), batch], dim=1)\n",
    "\n",
    "\n",
    "def mean_error_transformer(transformer, txt_batch, cmp_output_batch, max_seq_length):\n",
    "    generated_sequences_batch = generate_sequences_batch(transformer, txt_batch, max_length=max_seq_length)\n",
    "    return mean_error(generated_sequences_batch, add_start_token(cmp_output_batch))\n",
    "\n",
    "\n",
    "max_mean_error = max_seq_length / (max_seq_length + 1) # [!] not really exact\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:44:21.005598200Z",
     "start_time": "2024-02-15T15:44:20.959081600Z"
    }
   },
   "id": "352f5ebc86078e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequences Batch: tensor([[257, 150, 120,  33,  79,  38, 240,  83,  38, 240,  83, 141, 195,  69,\n",
      "         212,  69,  69, 212]], device='cuda:0')\n",
      "target sentence:  tensor([[257,  62,  65,   5, 133,  49,   3,  84, 209, 258, 258, 258, 258, 258,\n",
      "         258, 258, 258, 258]], device='cuda:0')\n",
      "0.9412393569946289\n"
     ]
    }
   ],
   "source": [
    "generated_sequences_batch = generate_sequences_batch(transformer, txt_example[0:1, :], max_length=max_seq_length)\n",
    "\n",
    "print(\"Generated Sequences Batch:\", generated_sequences_batch)\n",
    "print(\"target sentence: \", replace_padding_by_end_token(add_start_token(cmp_output_example[0:1, :])))\n",
    "print(mean_error_transformer(transformer, txt_example[:, :], cmp_output_example[:, :], max_seq_length))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:44:25.010767600Z",
     "start_time": "2024-02-15T15:44:23.678306300Z"
    }
   },
   "id": "8e4355c5610b3ca9"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, save_path=\"metrics.csv\", period=100):\n",
    "        self.save_path = save_path\n",
    "        self.period = period\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if (trainer.current_epoch + 1) % self.period == 0:\n",
    "            metrics = trainer.callback_metrics\n",
    "            print(\"Epoch Loss: \", metrics.get('train_loss', 0).item())\n",
    "            \n",
    "            row = {\n",
    "                'epoch': trainer.current_epoch + 1,\n",
    "                'train_loss': metrics.get('train_loss', 0).item(),\n",
    "                'levenshtein_score': metrics.get('levenshtein_score', 0).item(),\n",
    "                'unzip_score': metrics.get('unzip_score', 0).item(),\n",
    "            }\n",
    "            file_exists = os.path.isfile(self.save_path)\n",
    "            with open(self.save_path, mode='a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()  # Write header only once\n",
    "                writer.writerow(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T17:47:29.661117600Z",
     "start_time": "2024-02-15T17:47:29.628226400Z"
    }
   },
   "id": "2b5ea4da68b2b4c9"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | encoder_embedding   | Embedding          | 132 K \n",
      "1 | decoder_embedding   | Embedding          | 132 K \n",
      "2 | positional_encoding | PositionalEncoding | 0     \n",
      "3 | encoder_layers      | ModuleList         | 18.9 M\n",
      "4 | decoder_layers      | ModuleList         | 25.2 M\n",
      "5 | fc                  | Linear             | 132 K \n",
      "6 | dropout             | Dropout            | 0     \n",
      "7 | criterion           | CrossEntropyLoss   | 0     \n",
      "8 | accuracy            | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------------\n",
      "44.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.5 M    Total params\n",
      "178.146   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4bfdbd414b0441fa5859c0a92ebcde3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# print(isinstance(transformer, L.LightningModule))\n",
    "save_period = 2\n",
    "\n",
    "trainer = L.Trainer(limit_train_batches=5, max_epochs=2, log_every_n_steps= 1)\n",
    "trainer.fit(model=transformer, train_dataloaders=lz77_train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T17:48:39.605362500Z",
     "start_time": "2024-02-15T17:48:21.112427700Z"
    }
   },
   "id": "1e3e1f80e24d4898"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(5.1255)}\n"
     ]
    }
   ],
   "source": [
    "print(trainer.logged_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:50:20.826650700Z",
     "start_time": "2024-02-15T15:50:20.744968100Z"
    }
   },
   "id": "ee98fac471744c25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
